<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="PointPatchRL project page">
  <meta name="keywords" content="Reinforcement Learning, Point Clouds, Representation Learning, Masked Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PointPatchRL</title>

  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/patch_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              PointPatchRL - Masked Reconstruction Improves Reinforcement Learning on Point Clouds
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_527.php target="_blank">Bal√°zs Gyenes</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                Nikolai Franke<sup>1</sup>,
              </span>
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_72.php target=_blank>Philipp Becker</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_65.php target=_blank>Gerhard Neumann</a><sup>1,2</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Autonomous Learning Robots (ALR), Karlsruhe Institute of Technology (KIT)
              </span>
              <span class="author-block">
                <sup>2</sup>HIDSS4Health - Helmholtz Information and Data Science School for Health
              </span>
            </div>

            <div class="column has-text-centered">
              <h2 class="title is-4">CoRL 2024 Spotlight</h2>
              <div class="publication-links">
                <!-- OpenReview Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/forum?id=3jNEz3kUSl"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-comments"></i>
                    </span>
                    <span>OpenReview</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.18800" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/balazsgyenes/pprl"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://youtu.be/nGQK7yMA75E" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Spotlight Video</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="./pdf/poster.pdf" class="button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-table-columns"></i>
                    </span>
                    <span>Poster</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/papers/2410.18800"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-face-smile-beam"></i>
                    </span>
                    <span>Hugging Face Page</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <h2 class="subtitle has-text-centered">
        <!-- <b>PointPatchRL</b> builds on the common paradigm of dividing point clouds into overlapping patches, tokenizing them, and processing the tokens with transformers.
        We further add a masked reconstruction objective for representation learning, which masks out some of these tokens and tries to reconstruct the missing point patches.
        PointPatchRL provides significant improvements across the 6 environments we tested compared to point cloud-based and image-based baselines, and our policies generalize across variable object geometries. -->
      </h2>

      <!-- Top: We train a patching-based tokenizer and transformer encoder to compute a latent embedding for the RL policy
      and state-action-value estimation using sequence pooling. The
      entire pipeline learns using the critic's gradients while we detach the latent embedding before pro-
      viding it to the actor. Bottom: We augment the policy learning using masked reconstruction. Using
      the token sorting, masking, and transformer decoder introduced by PointGPT, we minimize the
      Chamfer distance for the point's positions and the mean squared reconstruction error for colors. This
      auxiliary loss provides an additional training signal for the shared encoder and tokenizer, improving
      RL performance and sample efficiency. -->
    </div>
    </div>
  </section>

  <!-- Abstract. -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <img src="./static/images/figure_overview.png">
          <div class="content has-text-justified">
            <p>
              PointPatchRL is a method for Reinforcement Learning on point clouds that harnesses their 3D structure to
              extract task-relevant geometric information from the scene and learn complex manipulation tasks purely
              from rewards.
            </p>
            <p>
              While images are a convenient format for perceiving the environment for RL, they often complicate
              extracting important geometric details, especially with <b>varying geometries</b> or <b>deformable
                objects</b>.
              In contrast, <b>point clouds</b> naturally represent this geometry and easily integrate positional and
              color data from <b>multiple camera views</b>.
              However, while deep learning on point clouds has seen many recent successes, RL on point clouds is
              under-researched, with usually only the simplest encoder architecture considered in the literature.
            </p>
            <p>
              We introduce <b>PointPatchRL (PPRL)</b>, a method for RL on point clouds that builds on the common
              paradigm
              of dividing point clouds into <b>overlapping patches</b>, <b>tokenizing</b> them, and processing the
              tokens
              with <b>transformers</b>.
              PPRL provides significant improvements compared with other point-cloud architectures previously used for
              RL.
              We then complement PPRL with <b>masked reconstruction</b> for representation learning and show that our
              method outperforms strong model-free and model-based baselines on image observations in complex
              manipulation
              tasks containing deformable objects and variations in target object geometry.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <h2 class="title is-3">Why Point Clouds?</h2>

          <div style="display: flex; align-items: center; justify-content: space-between; margin: 20px;">
            <img src="./static/gifs/pointclouds/turnfaucet_5004_2.gif" alt="A pointcloud of one faucet"
              style="max-width: 20%; height: auto; margin-right: 20px;">
            <img src="./static/gifs/pointclouds/turnfaucet_5000_1.gif"
              alt="A pointcloud of a completely different faucet"
              style="max-width: 20%; height: auto; margin-right: 20px;">
            <div style="flex: 1; text-align: left;">
              <p>
                Easier to extract task-relevant geometry
              </p>
            </div>
          </div>

          <div style="display: flex; align-items: center; justify-content: space-between; margin: 20px;">
            <img src="./static/gifs/pointclouds/turnfaucet_5010_1.gif"
              style="max-width: 20%; height: auto; margin-left: calc(10% + 10px); margin-right: calc(10% + 10px + 20px);">
            <div style="flex: 1; text-align: left;">
              <p>
                Disentangle occluded objects from their occluders
              </p>
            </div>
          </div>

          <div class="container" style="display: flex; align-items: center; margin: 20px;">
            <div
              style="width: 40%; margin-right: calc(20px + 20px); display: flex; flex-direction: column; align-items: center;">
              <div style="display: flex; align-items: center; justify-content: center; width: 100%">
                <img src="./static/gifs/pointclouds/TurnFaucet_5011_base_2024-10-22_04-40-02.png"
                  alt="A faucet from one perspective" style="width: 40%; height: auto;">
                <span style="margin: 0 5px; font-size: 24px; font-weight: bold;">+</span>
                <img src="./static/gifs/pointclouds/TurnFaucet_5011_hand_2024-10-22_04-40-21.png"
                  alt="The same faucet from a different perspective" style="width: 43%; height: auto;">
              </div>
              <div style="margin-top: 5px; width: 100%; display: flex; justify-content: center;">
                <img src="./static/gifs/pointclouds/turnfaucet_5011_1.gif" alt="GIF Description"
                  style="width: 50%; height: auto;">
              </div>
            </div>
            <div style="flex: 1; text-align: left;">
              <p>
                Combine multiple camera views
              </p>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{gyenes2024pointpatchrl,
  title={PointPatch{RL} - Masked Reconstruction Improves Reinforcement Learning on Point Clouds},
  author={Bal{\'a}zs Gyenes and Nikolai Franke and Philipp Becker and Gerhard Neumann},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
  url={https://openreview.net/forum?id=3jNEz3kUSl}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website template was borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>