<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="PointPatchRL project page">
  <meta name="keywords" content="Reinforcement Learning, Point Clouds, Representation Learning, Masked Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PointPatchRL</title>

  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/patch_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              PointPatchRL - Masked Reconstruction Improves Reinforcement Learning on Point Clouds
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_527.php target="_blank">Bal√°zs Gyenes</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                Nikolai Franke<sup>1</sup>,
              </span>
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_72.php target=_blank>Philipp Becker</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href=https://alr.iar.kit.edu/21_65.php target=_blank>Gerhard Neumann</a><sup>1,2</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Autonomous Learning Robots (ALR), Karlsruhe Institute of Technology (KIT)
              </span>
              <span class="author-block">
                <sup>2</sup>HIDSS4Health - Helmholtz Information and Data Science School for Health
              </span>
            </div>

            <div class="column has-text-centered">
              <h2 class="title is-4">CoRL 2024 Spotlight</h2>
              <div class="publication-links">
                <!-- OpenReview Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/forum?id=3jNEz3kUSl"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-comments"></i>
                    </span>
                    <span>OpenReview</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.18800" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/balazsgyenes/pprl"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://youtu.be/nGQK7yMA75E" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Spotlight Video</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="./pdf/poster.pdf" class="button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-table-columns"></i>
                    </span>
                    <span>Poster</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/papers/2410.18800"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-face-smile-beam"></i>
                    </span>
                    <span>Hugging Face Page</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <h2 class="subtitle has-text-centered">
        <!-- <b>PointPatchRL</b> builds on the common paradigm of dividing point clouds into overlapping patches, tokenizing them, and processing the tokens with transformers.
        We further add a masked reconstruction objective for representation learning, which masks out some of these tokens and tries to reconstruct the missing point patches.
        PointPatchRL provides significant improvements across the 6 environments we tested compared to point cloud-based and image-based baselines, and our policies generalize across variable object geometries. -->
      </h2>

      <!-- Top: We train a patching-based tokenizer and transformer encoder to compute a latent embedding for the RL policy
      and state-action-value estimation using sequence pooling. The
      entire pipeline learns using the critic's gradients while we detach the latent embedding before pro-
      viding it to the actor. Bottom: We augment the policy learning using masked reconstruction. Using
      the token sorting, masking, and transformer decoder introduced by PointGPT, we minimize the
      Chamfer distance for the point's positions and the mean squared reconstruction error for colors. This
      auxiliary loss provides an additional training signal for the shared encoder and tokenizer, improving
      RL performance and sample efficiency. -->
    </div>
    </div>
  </section>

  <!-- Abstract. -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <img src="./static/images/figure_overview.png">
          <div class="content has-text-justified">
            <p>
              PointPatchRL is a method for Reinforcement Learning on point clouds that harnesses their 3D structure to
              extract task-relevant geometric information from the scene and learn complex manipulation tasks purely
              from rewards.
            </p>
            <p>
              While images are a convenient format for perceiving the environment for RL, they often complicate
              extracting important geometric details, especially with <b>varying geometries</b> or <b>deformable
                objects</b>.
              In contrast, <b>point clouds</b> naturally represent this geometry and easily integrate positional and
              color data from <b>multiple camera views</b>.
              However, while deep learning on point clouds has seen many recent successes, RL on point clouds is
              under-researched, with usually only the simplest encoder architecture considered in the literature.
            </p>
            <p>
              We introduce <b>PointPatchRL (PPRL)</b>, a method for RL on point clouds that builds on the common
              paradigm
              of dividing point clouds into <b>overlapping patches</b>, <b>tokenizing</b> them, and processing the
              tokens
              with <b>transformers</b>.
              PPRL provides significant improvements compared with other point-cloud architectures previously used for
              RL.
              We then complement PPRL with <b>masked reconstruction</b> for representation learning and show that our
              method outperforms strong model-free and model-based baselines on image observations in complex
              manipulation
              tasks containing deformable objects and variations in target object geometry.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Why Point Clouds? -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <h2 class="title is-3">Why Point Clouds?</h2>

          <div style="display: flex; align-items: center; justify-content: space-between; margin: 20px;">
            <img src="./static/gifs/pointclouds/turnfaucet_5004_2.gif" alt="A pointcloud of one faucet"
              style="max-width: 20%; height: auto; margin-right: 2%;">
            <img src="./static/gifs/pointclouds/turnfaucet_5000_1.gif"
              alt="A pointcloud of a completely different faucet"
              style="max-width: 20%; height: auto; margin-right: 20px;">
            <div style="flex: 1; text-align: left;">
              <p>
                Easier to extract task-relevant geometry
              </p>
            </div>
          </div>

          <div style="display: flex; align-items: center; justify-content: space-between; margin: 20px;">
            <img src="./static/gifs/pointclouds/turnfaucet_5010_1.gif"
              style="max-width: 30%; height: auto; margin-left: 6%; margin-right: calc(6% + 20px);">
            <div style="flex: 1; text-align: left;">
              <p>
                Disentangle occluded objects from their occluders
              </p>
            </div>
          </div>

          <div class="container" style="display: flex; align-items: center; margin: 20px;">
            <div
              style="width: 42%; margin-right: 20px; display: flex; flex-direction: column; align-items: center;">
              <div style="display: flex; align-items: center; justify-content: center; width: 100%">
                <img src="./static/gifs/pointclouds/TurnFaucet_5011_base_2024-10-22_04-40-02.png"
                  alt="A faucet from one perspective" style="width: 40%; height: auto;">
                <span style="margin: 0 1%; font-size: 24px; font-weight: bold;">+</span>
                <img src="./static/gifs/pointclouds/TurnFaucet_5011_hand_2024-10-22_04-40-21.png"
                  alt="The same faucet from a different perspective" style="width: 43%; height: auto;">
              </div>
              <div style="margin-top: 2%; width: 100%; display: flex; justify-content: center;">
                <img src="./static/gifs/pointclouds/turnfaucet_5011_1.gif"
                  alt="A point cloud made from combining both perspectives" style="width: 50%; height: auto;">
              </div>
            </div>
            <div style="flex: 1; text-align: left;">
              <p>
                Combine multiple camera views
              </p>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>

  <!-- Method -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method</h2>
      <div class="columns is-centered">

        <!-- PointPatchRL. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-4">PointPatchRL</h2>
            <p>
              PointPatchRL is a powerful point cloud encoder in its own right, due to the well-known patching and
              tokenizing paradigm.
              As a simple, drop-in replacement for any other point cloud encoder, PointPatchRL increases sample
              efficiency compared to commonly-used architectures (like PointNet).
              No need to add a reconstruction loss to the learning pipeline if not desired!
            </p>
            <img src="./static/images/overview_noreconstruction.png"
              alt="PointPatchRL is a powerful point cloud encoder in its own right" style="width: 95%; height: auto;">
          </div>
        </div>
        <!--/ PointPatchRL. -->

        <!-- PointPatchRL + Aux. -->
        <div class="column">
          <h2 class="title is-4">PointPatchRL + Aux</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                We can add to the strong baseline provided by PointPatchRL by introducing the auto-regressive masked
                reconstruction loss used in PointGPT.
                This results in even greater sample efficiency on complex manipulation tasks with multiple (potentially
                moving) cameras.
                PointPatchRL + Aux outperforms both point cloud-based and image-based baselines.
              </p>
              <img src="./static/images/figure_overview.png"
                alt="PointPatchRL + Aux is superior to point cloud-based and image-based baselines"
                style="width: 100%; height: auto;">
            </div>

          </div>
        </div>
        <!--/ PointPatchRL + Aux. -->

      </div>
    </div>
  </section>
  <!--/ Method -->

  <!-- Policy Videos. -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Policy Videos</h2>
      <p>
        Our method outperforms point cloud-based and image-based baselines on 6 challenging manipulation tasks.
        The tasks contain either deformable objects, or geometric variations across a set of rigid objects.
      </p>
      <div class="columns is-centered">
        <div style="display: grid;
                    grid-template-columns: repeat(3, minmax(50px, 1fr));
                    grid-template-rows: repeat(2, auto);
                    gap: 16px;
                    padding: 20px;
                    background: white;
                    border: 2px solid #ddd;
                    border-radius: 8px;
                    margin-top: 20px;">
          <!-- &shy; tells the browser where to break the word when wrapping a line -->
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/threadinhole1.gif" alt="ThreadInHole env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Thread&shy;In&shy;Hole</figcaption>
          </figure>
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/deflectspheres2.gif" alt="DeflectSpheres env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Deflect&shy;Spheres</figcaption>
          </figure>
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/pushchair2.gif" alt="PushChair env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Push&shy;Chair</figcaption>
          </figure>
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/opencabinetdrawer2.gif" alt="OpenCabinetDrawer env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Open&shy;Cabinet&shy;Drawer</figcaption>
          </figure>
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/opencabinetdoor2.gif" alt="OpenCabinerDoor env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Open&shy;Cabiner&shy;Door</figcaption>
          </figure>
          <figure style="display: flex; flex-direction: column; align-items: center; text-align: center;">
            <img src="./static/gifs/envs/turnfaucet1.gif" alt="TurnFaucet env"
              style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
            <figcaption style="overflow-wrap: break-word; margin-top: 8px; font-size: 14px; color: #555;">Turn&shy;Faucet</figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>
  <!--/ Policy Videos. -->

  <!-- Diverse Policies. -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Diverse Policies</h2>
      <p>
        Agents trained with PPRL + Aux adapt to varying geometries, including handle size and orientation, and whether
        the door opens to the left or right.
        The policy coordinates the movements of the gripper and the base and generalizes over varying object geometry.
      </p>
      <div class="columns is-centered">
        <div style="display: grid;
                    grid-template-columns: repeat(3, 1fr);
                    grid-template-rows: repeat(2, auto);
                    gap: 16px;
                    padding: 20px;
                    background: white;
                    border: 2px solid #ddd;
                    border-radius: 8px;
                    margin-top: 20px;">
          <img src="./static/gifs/diverse_policies/bhARCSI2.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <img src="./static/gifs/diverse_policies/cmwSBT3N.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <img src="./static/gifs/diverse_policies/IOJ7rDaa.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <img src="./static/gifs/diverse_policies/pFO7GNf8.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <img src="./static/gifs/diverse_policies/y9HQFZsL.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <img src="./static/gifs/diverse_policies/Yhlnfvi1.gif"
            style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
        </div>
      </div>
    </div>
  </section>
  <!--/ Diverse Policies. -->

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{gyenes2024pointpatchrl,
  title={PointPatch{RL} - Masked Reconstruction Improves Reinforcement Learning on Point Clouds},
  author={Bal{\'a}zs Gyenes and Nikolai Franke and Philipp Becker and Gerhard Neumann},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
  url={https://openreview.net/forum?id=3jNEz3kUSl}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website template was borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>